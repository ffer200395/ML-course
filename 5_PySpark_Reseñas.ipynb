{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/blH9lTU7ZOYqTveHy/Xe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffer200395/ML-course/blob/main/5_PySpark_Rese%C3%B1as.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QXWmrjdQC1s",
        "outputId": "71f99932-273b-41ed-9c65-fc17fb106daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 39 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 29.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=924140c72e4e98f0a691aca5213e65e83796a88c4fb189f97919fb062e9c3d29\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "# Instalamos el framework pySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from google.colab import drive\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "D1qUPWDlQeHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Python Spark Reseñas\").getOrCreate()"
      ],
      "metadata": {
        "id": "i82UIOEiQssB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path\n",
        "path = '/content/gdrive/MyDrive/Colab Notebooks/Formación Python y ML'\n",
        "# Mount drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37g7fjVnRHmS",
        "outputId": "5753ca14-c44b-482e-9679-ace808f8d0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = spark.read.options(delimiter=\",\", header=True,escape=\"\\\"\").csv(path+'/IMDB Dataset.csv')\n",
        "df_spark.printSchema()\n",
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyRk1ELDRQeA",
        "outputId": "715067ce-b453-4172-fb0f-eef68cea050c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review: string (nullable = true)\n",
            " |-- sentiment: string (nullable = true)\n",
            "\n",
            "+--------------------+---------+\n",
            "|              review|sentiment|\n",
            "+--------------------+---------+\n",
            "|One of the other ...| positive|\n",
            "|A wonderful littl...| positive|\n",
            "|I thought this wa...| positive|\n",
            "|Basically there's...| negative|\n",
            "|Petter Mattei's \"...| positive|\n",
            "|Probably my all-t...| positive|\n",
            "|I sure would like...| positive|\n",
            "|This show was an ...| negative|\n",
            "|Encouraged by the...| negative|\n",
            "|If you like origi...| positive|\n",
            "|Phil the Alien is...| negative|\n",
            "|I saw this movie ...| negative|\n",
            "|So im not a big f...| negative|\n",
            "|The cast played S...| negative|\n",
            "|This a fantastic ...| positive|\n",
            "|Kind of drawn in ...| negative|\n",
            "|Some films just s...| positive|\n",
            "|This movie made i...| negative|\n",
            "|I remember this f...| positive|\n",
            "|An awful film! It...| negative|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos la variable respuesta en formato numérico \n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"sentiment_enc\") \n",
        "indexed = indexer.fit(df_spark).transform(df_spark) \n",
        "indexed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrbjU9PbYqNv",
        "outputId": "75b18a2e-9c2d-41ba-a5be-eedfa667865f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------------+\n",
            "|              review|sentiment|sentiment_enc|\n",
            "+--------------------+---------+-------------+\n",
            "|One of the other ...| positive|          1.0|\n",
            "|A wonderful littl...| positive|          1.0|\n",
            "|I thought this wa...| positive|          1.0|\n",
            "|Basically there's...| negative|          0.0|\n",
            "|Petter Mattei's \"...| positive|          1.0|\n",
            "|Probably my all-t...| positive|          1.0|\n",
            "|I sure would like...| positive|          1.0|\n",
            "|This show was an ...| negative|          0.0|\n",
            "|Encouraged by the...| negative|          0.0|\n",
            "|If you like origi...| positive|          1.0|\n",
            "|Phil the Alien is...| negative|          0.0|\n",
            "|I saw this movie ...| negative|          0.0|\n",
            "|So im not a big f...| negative|          0.0|\n",
            "|The cast played S...| negative|          0.0|\n",
            "|This a fantastic ...| positive|          1.0|\n",
            "|Kind of drawn in ...| negative|          0.0|\n",
            "|Some films just s...| positive|          1.0|\n",
            "|This movie made i...| negative|          0.0|\n",
            "|I remember this f...| positive|          1.0|\n",
            "|An awful film! It...| negative|          0.0|\n",
            "+--------------------+---------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingeniería de características\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "\n",
        "# Dejamos solo palabras\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"review\", outputCol=\"tokens\", pattern=\"\\\\W\", toLowercase = True, minTokenLength = 3)\n",
        "df_tokens = regexTokenizer.transform(indexed)\n",
        "df_tokens.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSpU8zQvaibe",
        "outputId": "7d86f6f1-748f-410d-9781-957fefa0db0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------------+--------------------+\n",
            "|              review|sentiment|sentiment_enc|              tokens|\n",
            "+--------------------+---------+-------------+--------------------+\n",
            "|One of the other ...| positive|          1.0|[one, the, other,...|\n",
            "|A wonderful littl...| positive|          1.0|[wonderful, littl...|\n",
            "|I thought this wa...| positive|          1.0|[thought, this, w...|\n",
            "|Basically there's...| negative|          0.0|[basically, there...|\n",
            "|Petter Mattei's \"...| positive|          1.0|[petter, mattei, ...|\n",
            "|Probably my all-t...| positive|          1.0|[probably, all, t...|\n",
            "|I sure would like...| positive|          1.0|[sure, would, lik...|\n",
            "|This show was an ...| negative|          0.0|[this, show, was,...|\n",
            "|Encouraged by the...| negative|          0.0|[encouraged, the,...|\n",
            "|If you like origi...| positive|          1.0|[you, like, origi...|\n",
            "|Phil the Alien is...| negative|          0.0|[phil, the, alien...|\n",
            "|I saw this movie ...| negative|          0.0|[saw, this, movie...|\n",
            "|So im not a big f...| negative|          0.0|[not, big, fan, b...|\n",
            "|The cast played S...| negative|          0.0|[the, cast, playe...|\n",
            "|This a fantastic ...| positive|          1.0|[this, fantastic,...|\n",
            "|Kind of drawn in ...| negative|          0.0|[kind, drawn, the...|\n",
            "|Some films just s...| positive|          1.0|[some, films, jus...|\n",
            "|This movie made i...| negative|          0.0|[this, movie, mad...|\n",
            "|I remember this f...| positive|          1.0|[remember, this, ...|\n",
            "|An awful film! It...| negative|          0.0|[awful, film, mus...|\n",
            "+--------------------+---------+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_remover = StopWordsRemover(inputCol='tokens',outputCol='filtered_tokens',stopWords=['this','these','that','those','the','and'])\n",
        "df_sw = stopwords_remover.transform(df_tokens)\n",
        "df_sw.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RQ-1s6ecv2a",
        "outputId": "ab09a9b3-f3c4-4b0e-8e4e-af6ab92e99bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------------+--------------------+--------------------+\n",
            "|              review|sentiment|sentiment_enc|              tokens|     filtered_tokens|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+\n",
            "|One of the other ...| positive|          1.0|[one, the, other,...|[one, other, revi...|\n",
            "|A wonderful littl...| positive|          1.0|[wonderful, littl...|[wonderful, littl...|\n",
            "|I thought this wa...| positive|          1.0|[thought, this, w...|[thought, was, wo...|\n",
            "|Basically there's...| negative|          0.0|[basically, there...|[basically, there...|\n",
            "|Petter Mattei's \"...| positive|          1.0|[petter, mattei, ...|[petter, mattei, ...|\n",
            "|Probably my all-t...| positive|          1.0|[probably, all, t...|[probably, all, t...|\n",
            "|I sure would like...| positive|          1.0|[sure, would, lik...|[sure, would, lik...|\n",
            "|This show was an ...| negative|          0.0|[this, show, was,...|[show, was, amazi...|\n",
            "|Encouraged by the...| negative|          0.0|[encouraged, the,...|[encouraged, posi...|\n",
            "|If you like origi...| positive|          1.0|[you, like, origi...|[you, like, origi...|\n",
            "|Phil the Alien is...| negative|          0.0|[phil, the, alien...|[phil, alien, one...|\n",
            "|I saw this movie ...| negative|          0.0|[saw, this, movie...|[saw, movie, when...|\n",
            "|So im not a big f...| negative|          0.0|[not, big, fan, b...|[not, big, fan, b...|\n",
            "|The cast played S...| negative|          0.0|[the, cast, playe...|[cast, played, sh...|\n",
            "|This a fantastic ...| positive|          1.0|[this, fantastic,...|[fantastic, movie...|\n",
            "|Kind of drawn in ...| negative|          0.0|[kind, drawn, the...|[kind, drawn, ero...|\n",
            "|Some films just s...| positive|          1.0|[some, films, jus...|[some, films, jus...|\n",
            "|This movie made i...| negative|          0.0|[this, movie, mad...|[movie, made, int...|\n",
            "|I remember this f...| positive|          1.0|[remember, this, ...|[remember, film, ...|\n",
            "|An awful film! It...| negative|          0.0|[awful, film, mus...|[awful, film, mus...|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos un conteo de las palabras en cada review\n",
        "vectorizer = CountVectorizer(inputCol='filtered_tokens',outputCol='rawFeatures',maxDF=.8,minDF=.05,binary=True)\n",
        "df_vect = vectorizer.fit(df_sw).transform(df_sw)\n",
        "df_vect.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_fVjbgDfC1Z",
        "outputId": "7a6580df-d49f-47a1-f2dc-438e5e7e0acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+\n",
            "|              review|sentiment|sentiment_enc|              tokens|     filtered_tokens|         rawFeatures|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+\n",
            "|One of the other ...| positive|          1.0|[one, the, other,...|[one, other, revi...|(390,[0,2,3,4,6,7...|\n",
            "|A wonderful littl...| positive|          1.0|[wonderful, littl...|[wonderful, littl...|(390,[3,4,6,7,8,9...|\n",
            "|I thought this wa...| positive|          1.0|[thought, this, w...|[thought, was, wo...|(390,[0,3,4,7,8,9...|\n",
            "|Basically there's...| negative|          0.0|[basically, there...|[basically, there...|(390,[1,2,3,5,6,8...|\n",
            "|Petter Mattei's \"...| positive|          1.0|[petter, mattei, ...|[petter, mattei, ...|(390,[1,2,3,4,5,7...|\n",
            "|Probably my all-t...| positive|          1.0|[probably, all, t...|[probably, all, t...|(390,[1,2,4,7,8,1...|\n",
            "|I sure would like...| positive|          1.0|[sure, would, lik...|[sure, would, lik...|(390,[2,3,6,10,13...|\n",
            "|This show was an ...| negative|          0.0|[this, show, was,...|[show, was, amazi...|(390,[0,2,3,4,7,8...|\n",
            "|Encouraged by the...| negative|          0.0|[encouraged, the,...|[encouraged, posi...|(390,[0,2,5,9,10,...|\n",
            "|If you like origi...| positive|          1.0|[you, like, origi...|[you, like, origi...|(390,[1,6,8,16,32...|\n",
            "|Phil the Alien is...| negative|          0.0|[phil, the, alien...|[phil, alien, one...|(390,[0,1,2,4,5,1...|\n",
            "|I saw this movie ...| negative|          0.0|[saw, this, movie...|[saw, movie, when...|(390,[0,1,2,4,5,7...|\n",
            "|So im not a big f...| negative|          0.0|[not, big, fan, b...|[not, big, fan, b...|(390,[0,1,2,3,4,5...|\n",
            "|The cast played S...| negative|          0.0|[the, cast, playe...|[cast, played, sh...|(390,[0,1,4,6,7,1...|\n",
            "|This a fantastic ...| positive|          1.0|[this, fantastic,...|[fantastic, movie...|(390,[1,4,7,11,14...|\n",
            "|Kind of drawn in ...| negative|          0.0|[kind, drawn, the...|[kind, drawn, ero...|(390,[0,3,4,5,6,1...|\n",
            "|Some films just s...| positive|          1.0|[some, films, jus...|[some, films, jus...|(390,[0,2,3,4,5,6...|\n",
            "|This movie made i...| negative|          0.0|[this, movie, mad...|[movie, made, int...|(390,[0,1,2,3,4,7...|\n",
            "|I remember this f...| positive|          1.0|[remember, this, ...|[remember, film, ...|(390,[0,5,10,11,1...|\n",
            "|An awful film! It...| negative|          0.0|[awful, film, mus...|[awful, film, mus...|(390,[2,3,4,5,7,1...|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainDF,testDF) = df_vect.randomSplit((0.9,0.1),seed=42)"
      ],
      "metadata": {
        "id": "-YmRCpukilpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"sentiment_enc\", featuresCol=\"rawFeatures\", numTrees=10)\n",
        "df_yhat= rf.fit(trainDF).transform(trainDF)"
      ],
      "metadata": {
        "id": "z4IxXUfMiqXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_yhat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppeBACzdkbvj",
        "outputId": "77290d3a-2789-420a-ac28-176fbe28db97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|              review|sentiment|sentiment_enc|              tokens|     filtered_tokens|         rawFeatures|       rawPrediction|         probability|prediction|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|\\b\\b\\b\\bA Turkish...| positive|          1.0|[turkish, bath, s...|[turkish, bath, s...|(390,[0,1,2,3,4,5...|[4.96418616765674...|[0.49641861676567...|       1.0|\n",
            "|!!!! MILD SPOILER...| negative|          0.0|[mild, spoilers, ...|[mild, spoilers, ...|(390,[1,2,3,4,6,7...|[4.13816108671745...|[0.41381610867174...|       1.0|\n",
            "|!!!! MILD SPOILER...| negative|          0.0|[mild, spoilers, ...|[mild, spoilers, ...|(390,[0,1,2,3,4,5...|[5.88587928037525...|[0.58858792803752...|       0.0|\n",
            "|!!!! POSSIBLE MIL...| negative|          0.0|[possible, mild, ...|[possible, mild, ...|(390,[0,2,3,4,5,9...|[5.21397792532023...|[0.52139779253202...|       0.0|\n",
            "|\" Now in India's ...| positive|          1.0|[now, india, sunn...|[now, india, sunn...|(390,[1,2,3,5,6,8...|[4.69571510932641...|[0.46957151093264...|       1.0|\n",
            "|\" Så som i himmel...| positive|          1.0|[som, himmelen, a...|[som, himmelen, a...|(390,[0,5,6,9,12,...|[3.19887357874816...|[0.31988735787481...|       1.0|\n",
            "|\"... the beat is ...| positive|          1.0|[the, beat, too, ...|[beat, too, stron...|(390,[1,2,3,4,5,6...|[6.54700021464072...|[0.65470002146407...|       0.0|\n",
            "|\"200l: A Space Od...| positive|          1.0|[200l, space, ody...|[200l, space, ody...|(390,[0,2,3,4,5,7...|[4.09933828769620...|[0.40993382876962...|       1.0|\n",
            "|\"8 SIMPLE RULES.....| positive|          1.0|[simple, rules, f...|[simple, rules, f...|(390,[0,2,4,6,7,9...|[4.47083436193427...|[0.44708343619342...|       1.0|\n",
            "|\"9/11,\" hosted by...| positive|          1.0|[hosted, robert, ...|[hosted, robert, ...|(390,[7,15,67,82,...|[4.69571510932641...|[0.46957151093264...|       1.0|\n",
            "|\"A Cry in the Dar...| positive|          1.0|[cry, the, dark, ...|[cry, dark, maste...|(390,[0,4,6,8,11,...|[5.23568413597122...|[0.52356841359712...|       0.0|\n",
            "|\"A Gentleman's Ga...| negative|          0.0|[gentleman, game,...|[gentleman, game,...|(390,[0,1,2,5,7,8...|[4.94994484799084...|[0.49499448479908...|       1.0|\n",
            "|\"A Guy Thing\" may...| positive|          1.0|[guy, thing, may,...|[guy, thing, may,...|(390,[3,4,5,6,7,9...|[6.79925807769347...|[0.67992580776934...|       0.0|\n",
            "|\"A Minute to Pray...| positive|          1.0|[minute, pray, se...|[minute, pray, se...|(390,[1,2,3,4,5,7...|[4.07036043396841...|[0.40703604339684...|       1.0|\n",
            "|\"A Mouse in the H...| positive|          1.0|[mouse, the, hous...|[mouse, house, ve...|(390,[2,3,4,6,8,1...|[4.68984596783041...|[0.46898459678304...|       1.0|\n",
            "|\"A Slight Case of...| positive|          1.0|[slight, case, mu...|[slight, case, mu...|(390,[1,2,3,5,6,9...|[3.22373592031015...|[0.32237359203101...|       1.0|\n",
            "|\"A Tale of Two Si...| positive|          1.0|[tale, two, siste...|[tale, two, siste...|(390,[0,3,4,5,7,8...|[3.60446249212960...|[0.36044624921296...|       1.0|\n",
            "|\"A Thief in the N...| positive|          1.0|[thief, the, nigh...|[thief, night, fi...|(390,[0,1,3,4,5,7...|[4.69571510932641...|[0.46957151093264...|       1.0|\n",
            "|\"A bored televisi...| negative|          0.0|[bored, televisio...|[bored, televisio...|(390,[1,2,3,4,8,9...|[4.52135055694569...|[0.45213505569456...|       1.0|\n",
            "|\"A death at a col...| negative|          0.0|[death, college, ...|[death, college, ...|(390,[0,1,2,3,4,9...|[4.52135055694569...|[0.45213505569456...|       1.0|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='sentiment_enc',predictionCol='prediction',metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(df_yhat)"
      ],
      "metadata": {
        "id": "HG9prmC4mS17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2HI8XOSm3o1",
        "outputId": "dfb4e7f3-106a-437d-e87b-d792af8aa25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7462653437215601"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo mismo pero para el test\n",
        "df_yhat_test= rf.fit(trainDF).transform(testDF)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='sentiment_enc',predictionCol='prediction',metricName='accuracy')\n",
        "evaluator.evaluate(df_yhat_test)"
      ],
      "metadata": {
        "id": "4Y72gleAnCVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65083d90-8468-4f50-91d7-038dc48f0ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.743988684582744"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import *\n",
        "metrics = MulticlassMetrics(df_yhat_test.select(col(\"sentiment_enc\"),col(\"prediction\")))"
      ],
      "metadata": {
        "id": "guWlWEF8MBVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pipelines"
      ],
      "metadata": {
        "id": "OW3vfh5xNiX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use the pipeline to automate the process of machine learning from the process of feature engineering to model building.\n",
        "from pyspark.ml import Pipeline  \n",
        "# Ingeniería de características\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Dejamos solo palabras\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"review\", outputCol=\"tokens\", pattern=\"\\\\W\", toLowercase = True, minTokenLength = 3)\n",
        "stopwords_remover = StopWordsRemover(inputCol='tokens',outputCol='filtered_tokens',stopWords=['this','these','that','those','the','and'])\n",
        "# Realizamos un conteo de las palabras en cada review\n",
        "vectorizer = CountVectorizer(inputCol='filtered_tokens',outputCol='rawFeatures',maxDF=.8,minDF=.05,binary=True)\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"sentiment_enc\", featuresCol=\"rawFeatures\", numTrees=10)\n",
        "\n",
        "pipeline = Pipeline(stages=[regexTokenizer,stopwords_remover,vectorizer, rf])"
      ],
      "metadata": {
        "id": "3EiaO0ejNkE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainDF,testDF) = indexed.randomSplit((0.9,0.1),seed=42)"
      ],
      "metadata": {
        "id": "GVfL8-esPKjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipefit = pipeline.fit(trainDF)"
      ],
      "metadata": {
        "id": "taHO5MSdOGNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_train = pipefit.transform(trainDF)"
      ],
      "metadata": {
        "id": "rM7UXzufPiBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_test = pipefit.transform(testDF)"
      ],
      "metadata": {
        "id": "7ZSbdCoXQHuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_test.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcYhcLOgQma9",
        "outputId": "5ff655c8-8420-43d5-8a30-164c7129f49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|              review|sentiment|sentiment_enc|              tokens|     filtered_tokens|         rawFeatures|       rawPrediction|         probability|prediction|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|\" While sporadica...| negative|          0.0|[while, sporadica...|[while, sporadica...|(391,[0,3,5,6,8,1...|[5.49088004510498...|[0.54908800451049...|       0.0|\n",
            "|\"2001: A Space Od...| positive|          1.0|[2001, space, ody...|[2001, space, ody...|(391,[0,2,3,4,5,6...|[7.02264914942802...|[0.70226491494280...|       0.0|\n",
            "|\"Autumn Spring\" t...| positive|          1.0|[autumn, spring, ...|[autumn, spring, ...|(391,[2,3,4,5,6,9...|[4.58128353069765...|[0.45812835306976...|       1.0|\n",
            "|\"Bela Lugosi reve...| negative|          0.0|[bela, lugosi, re...|[bela, lugosi, re...|(391,[1,2,9,13,15...|[4.52300703759972...|[0.45230070375997...|       1.0|\n",
            "|\"Cat In The Brain...| positive|          1.0|[cat, the, brain,...|[cat, brain, seri...|(391,[0,1,2,3,4,5...|[5.89226835651493...|[0.58922683565149...|       0.0|\n",
            "|\"Cry Freedom\" is ...| positive|          1.0|[cry, freedom, no...|[cry, freedom, no...|(391,[1,4,5,7,9,1...|[4.31881285743037...|[0.43188128574303...|       1.0|\n",
            "|\"Death Wish 3\" is...| negative|          0.0|[death, wish, the...|[death, wish, mov...|(391,[1,8,12,15,1...|[4.82135781447920...|[0.48213578144792...|       1.0|\n",
            "|\"Deliverance\" is ...| positive|          1.0|[deliverance, dea...|[deliverance, dea...|(391,[0,1,2,3,4,5...|[5.59833312367595...|[0.55983331236759...|       0.0|\n",
            "|\"Don't bother to ...| negative|          0.0|[don, bother, wat...|[don, bother, wat...|(391,[0,2,4,5,6,7...|[4.66520509079680...|[0.46652050907968...|       1.0|\n",
            "|\"Fido\" is to be c...| positive|          1.0|[fido, commended,...|[fido, commended,...|(391,[2,4,5,8,10,...|[4.25128293434175...|[0.42512829343417...|       1.0|\n",
            "|\"Fraidy Cat\", the...| positive|          1.0|[fraidy, cat, the...|[fraidy, cat, 4th...|(391,[0,2,3,4,9,1...|[4.79590912955128...|[0.47959091295512...|       1.0|\n",
            "|\"Gone With The Wi...| negative|          0.0|[gone, with, the,...|[gone, with, wind...|(391,[0,1,2,3,5,6...|[6.56070054765667...|[0.65607005476566...|       0.0|\n",
            "|\"Haaaarrrryyy!\" <...| negative|          0.0|[haaaarrrryyy, th...|[haaaarrrryyy, am...|(391,[0,2,3,4,5,6...|[5.10427570237583...|[0.51042757023758...|       0.0|\n",
            "|\"Holes\" is my all...| positive|          1.0|[holes, all, time...|[holes, all, time...|(391,[0,1,2,5,10,...|[4.48407498523992...|[0.44840749852399...|       1.0|\n",
            "|\"I Am Curious: Ye...| negative|          0.0|[curious, yellow,...|[curious, yellow,...|(391,[2,3,4,5,6,7...|[4.95397738792190...|[0.49539773879219...|       1.0|\n",
            "|\"I like cheap per...| positive|          1.0|[like, cheap, per...|[like, cheap, per...|(391,[2,3,5,9,10,...|[4.72414926902147...|[0.47241492690214...|       1.0|\n",
            "|\"Jaded\" offers a ...| negative|          0.0|[jaded, offers, p...|[jaded, offers, p...|(391,[2,3,7,15,24...|[5.26067191844418...|[0.52606719184441...|       0.0|\n",
            "|\"Lifeforce\" is a ...| positive|          1.0|[lifeforce, truly...|[lifeforce, truly...|(391,[3,4,7,8,11,...|[3.79869156386203...|[0.37986915638620...|       1.0|\n",
            "|\"Lonely among us\"...| positive|          1.0|[lonely, among, d...|[lonely, among, d...|(391,[0,2,3,4,8,9...|[4.09075937498699...|[0.40907593749869...|       1.0|\n",
            "|\"MY WIFE AND KIDS...| positive|          1.0|[wife, and, kids,...|[wife, kids, opin...|(391,[0,2,4,6,8,9...|[5.10701212651627...|[0.51070121265162...|       0.0|\n",
            "+--------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "gsctU1X2Vusb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import ChiSqSelector\n",
        "selector=ChiSqSelector(numTopFeatures = 200, featuresCol='rawFeatures', outputCol='selectedFeatures', labelCol= 'sentiment_enc')\n",
        "model=selector.fit(yhat_train)"
      ],
      "metadata": {
        "id": "Vqm6s2NjWHqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features_train = model.transform(yhat_train)"
      ],
      "metadata": {
        "id": "l-oF7_3oWkDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features_test = model.transform(yhat_test)"
      ],
      "metadata": {
        "id": "uYXpSqHnWsNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"sentiment_enc\", featuresCol=\"selectedFeatures\", numTrees=10)\n",
        "rf_fit = rf.fit(df_features_train.select('selectedFeatures','sentiment_enc'))"
      ],
      "metadata": {
        "id": "BXK1q2i2W3uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_test_feat = rf_fit.transform(df_features_test.select('selectedFeatures','sentiment_enc'))"
      ],
      "metadata": {
        "id": "4sMW2POCXYZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_test_feat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7DcQoZKWxYh",
        "outputId": "4abdf7e6-32ee-48f4-829b-4ef11f9b3abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+--------------------+--------------------+----------+\n",
            "|    selectedFeatures|sentiment_enc|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-------------+--------------------+--------------------+----------+\n",
            "|(200,[0,3,6,7,8,9...|          0.0|[5.32930528748670...|[0.53293052874867...|       0.0|\n",
            "|(200,[0,2,3,4,5,6...|          1.0|[6.51130083531375...|[0.65113008353137...|       0.0|\n",
            "|(200,[2,3,5,6,8,2...|          1.0|[4.23837074142084...|[0.42383707414208...|       1.0|\n",
            "|(200,[1,5,7,9,14,...|          0.0|[4.23837074142084...|[0.42383707414208...|       1.0|\n",
            "|(200,[0,1,2,4,5,6...|          1.0|[6.03952647272759...|[0.60395264727275...|       0.0|\n",
            "|(200,[1,2,4,5,8,9...|          1.0|[5.62525093445323...|[0.56252509344532...|       0.0|\n",
            "|(200,[1,9,10,17,2...|          0.0|[4.52855757601603...|[0.45285575760160...|       1.0|\n",
            "|(200,[0,1,2,3,4,5...|          1.0|[3.51730666604509...|[0.35173066660450...|       1.0|\n",
            "|(200,[0,2,3,4,9,1...|          0.0|[6.38255404546619...|[0.63825540454661...|       0.0|\n",
            "|(200,[2,6,9,13,16...|          1.0|[4.40130368442733...|[0.44013036844273...|       1.0|\n",
            "|(200,[0,2,5,9,10,...|          1.0|[4.52855757601603...|[0.45285575760160...|       1.0|\n",
            "|(200,[0,1,3,4,5,8...|          0.0|[6.26172697593941...|[0.62617269759394...|       0.0|\n",
            "|(200,[0,2,3,5,6,8...|          0.0|[4.72658208870436...|[0.47265820887043...|       1.0|\n",
            "|(200,[0,1,6,22,25...|          1.0|[2.94473286227223...|[0.29447328622722...|       1.0|\n",
            "|(200,[2,3,4,7,9,1...|          0.0|[4.45335890220512...|[0.44533589022051...|       1.0|\n",
            "|(200,[5,6,8,9,12,...|          1.0|[4.23837074142084...|[0.42383707414208...|       1.0|\n",
            "|(200,[4,15,19,21,...|          0.0|[6.01978701276600...|[0.60197870127660...|       0.0|\n",
            "|(200,[2,4,7,9,16,...|          1.0|[3.82324787995571...|[0.38232478799557...|       1.0|\n",
            "|(200,[0,2,5,10,11...|          1.0|[4.35964657785005...|[0.43596465778500...|       1.0|\n",
            "|(200,[0,2,3,5,6,9...|          1.0|[4.40030822114825...|[0.44003082211482...|       1.0|\n",
            "+--------------------+-------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='sentiment_enc',predictionCol='prediction',metricName='accuracy')\n",
        "evaluator.evaluate(yhat_test_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsQ41kmcXxpH",
        "outputId": "9a9ae7d7-b574-4804-c310-62a4a7f616f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7395433420893109"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make new prediction\n",
        "from pyspark.sql.types import StringType\n",
        "ex1 = spark.createDataFrame([(\"'The movie was so interesting the best so far'\",StringType())],[\"review\"])\n",
        "pred_ex1 = pipefit.transform(ex1)"
      ],
      "metadata": {
        "id": "jhSwf2paodQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ex1.select('probability').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxlzfFChpfgs",
        "outputId": "3578eb0d-cf68-47e4-8579-002a38ddc564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------+\n",
            "|probability                            |\n",
            "+---------------------------------------+\n",
            "|[0.4396831634688273,0.5603168365311726]|\n",
            "+---------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}